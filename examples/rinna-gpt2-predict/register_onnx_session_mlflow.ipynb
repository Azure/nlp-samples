{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "from src.pyfunc_onnx import ONNXrinnaGPT2"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import os\n",
        "cache_dir = os.path.join(\".\", \"cache_models\")\n",
        "model_path = os.path.join(cache_dir, \"rinna_gpt2_beam_step_search_optimized_gpt2_int8.onnx\")\n",
        "\n",
        "onnx_gpt2 = ONNXrinnaGPT2(model_path)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628133878193
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "onnx_gpt2.predict('私はりんな')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text generation using OnnxRuntime ...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['私はりんな @audio_snowfox @audio_snowfox @audio_snowfox @au',\n",
              " '私はりんな @audio_snowfox ありがとうございます。',\n",
              " '私はりんな @audio_snowfox @audio_snowfox @audio_snowfox rt',\n",
              " '私はりんな @audio_snowfox ありがとうございます! @audio_snowfox ありがとうございます!']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628133928679
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "import os\n",
        "from azureml.core import Workspace\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "import mlflow\n",
        "\n",
        "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\")\n",
        "ws = Workspace.from_config(path='config.json',auth=interactive_auth)\n",
        "\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
        "\n",
        "experiment_name = \"rinna-gpt2-exp\"\n",
        "mlflow.set_experiment(experiment_name)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "conda_env = {\n",
        "    'name': 'mlflow-env',\n",
        "    'channels': ['conda-forge'],\n",
        "    'dependencies': [\n",
        "        'python=3.8.10',\n",
        "        'pip',\n",
        "        {'pip': [\n",
        "            'mlflow',\n",
        "            'cloudpickle==1.6.0',\n",
        "            'numpy',\n",
        "            'torch==1.9.0+cpu',\n",
        "            'torchvision==0.10.0+cpu',\n",
        "            'onnxruntime==1.8.1',\n",
        "            'sentencepiece',\n",
        "            'transformers==4.8.2',\n",
        "            'onnx',\n",
        "            'onnxconverter_common',\n",
        "            'psutil',\n",
        "            'pytz',\n",
        "            'pandas',\n",
        "            'py-cpuinfo',\n",
        "            'py3nvml',\n",
        "            'sympy', \n",
        "            'coloredlogs',\n",
        "            'azureml-core',\n",
        "            'azureml-mlflow'\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "\n",
        "client = mlflow.tracking.MlflowClient()\n",
        "\n",
        "registered_model = client.get_model_version(name='test-model',version=37)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "remote_model_path = os.path.join('outputs','onnx')\n",
        "mlflow.log_artifact(model_path, remote_model_path)\n",
        "model_uri = \"runs:/{}/\".format(registered_model.run_id) + remote_model_path # run_id を持っておけば with mlflow.start_run() as run は不要\n",
        "#mlflow.register_model(model_uri, 'rinna-GPT2-quantized_int8-model')\n",
        "mlflow.pyfunc.log_model(artifact_path='onnx/', python_model=onnx_gpt2, conda_env=conda_env, registered_model_name='onnx_beam')"
      ],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.8.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.11 64-bit ('rinna_gpt2_predict': conda)"
    },
    "metadata": {
      "interpreter": {
        "hash": "81098997110362167705b61d21e46dda767ff2050d805c22b6ba90fec7e1aa35"
      }
    },
    "kernel_info": {
      "name": "cpu_env"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "interpreter": {
      "hash": "1c4e185c907ad5151dcc0af21cbfea2685912d9386b07f96d5d5cb8de28dfd03"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}